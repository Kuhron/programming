2022-12-31

- product oriented schema neural net ideas: 
- word array is constant time length (columns, say 100) and constant number of articulators (rows). Each articulator e.g. blade, jaw, glottis, has a continuum of values in one dimension, from -1 to 1, where 0 is resting position (undefined/unspecified). Ignore discretization of place/voicing/etc. values for now. If articulator can move in more than one dimension, make separate row for each, e.g. tongue blade vs dorsum. The segments are placed in the array with equal width to fill the time (this is how to convert from a string e.g. "calor" (20 per seg) or "caliente" (~12.5 per seg) to a fixed-size input for non-recurrent NN, without words being likely to use up more space than 100 time units). Have function to convert from string in input paradigm to this array. NN will learn correspondence between word articulation array and semantics. Then get predicted form array from a meaning and have a function to convert it into some approximation of IPA symbols for each distinct feature set in the array. Might be able to get coarticulation effects this way.
- crazier idea that might be closer to the truth: anytime you have a function that converts between two things, use an NN for it instead, e.g. articulation array <-> string of phones, this could give rise to phonology naturally. But probably won't do this on first pass.
- maybe could use a known word vector embedding as the semantic space? designing my own using features still feels too top-down because of things like TAM bleeding across categories, want this to be possible in the NN's interpretation of meaning of a word. This is similar to "anytime you convert between two things, use a model to do so, not top-down logic".
- lexical and grammatical meaning are in the same semantic space, want things like "want" able to evolve to "not have", where the grammatical-like meaning of negation is subsumed into the root, or suppletion like "went" where one lexeme is more associated with past and another with nonpast.
- for semantic space, can use an existing word vector embedding like one made from a corpus of Spanish or Italian or something. Make a smallish list of verbs like "want", "have", "hold", etc. in all six persons, and hardcode their Spanish equivalents, and train the NN on the mapping from conlang form (articulation array) to Spanish meaning vector. What to do when it outputs a meaning in intermediate space when it sees a new form? Nearest neighbor? Or can we do things like analogous vector addition, e.g. we've seen V-er-esti and V-er-ebbe enough to know it's 2sg and 3sg conditional, and we get a form "canterebbe" that we've never seen, but we know "canteresti" is sing-2sg.cond, so how can I get it to infer that "canterebbe" has the same displacement vector from "canteresti" that "V-er-ebbe" has from "V-er-esti" in general? Or will it be able to do this on its own from knowing enough about the different parts of the words? Want a new input form to activate related-looking forms like "cant-er-X" and "V-er-ebbe" in the NN and then output an inference about the total meaning of the input form.
- How to get a clean interpretation of the meaning of an arbitrary vector in the space? Like the articulation array to string mapping, need a way for the human to intepret output. Maybe could show k nearest neighbors and their meanings and distances. Or could try collecting stats about displacement vectors for things like person marking (average over all such displacements over all lexemes?) and seeing how the new point could be approximated as a known meaning plus one or more of these displacements, but that already feels a bit more top-down. And the displacements may be erratic and lexeme-idiosyncratic rather than there being a clear thing like "add (0.1, -0.2, 0.45) to turn 2sg into 3sg while keeping lexeme and TAM constant" with low variance across lexemes and TAMs. The space could be more warped than that.
- Could also construct semantic space from a "corpus" of simple example utterances, like "I go", "you go", "he goes", "yesterday I went", etc. Build word vectors from this. Will be easier and cleaner than using Spanish corpus or something like that, but will also be less true to real semantics. Generate these utterances at random maybe? So we'll get slightly different embeddings each time, and some random set of possible forms will have been absent by chance, so the NN will have to figure out what they mean. Could use conlang words for Word2Vec or could use glosses to remove ambiguity, then get accurate vectors without homophony getting in the way. Then when training the NN on form-meaning correspondence, pick a gloss, then translate gloss to conlang form and convert gloss to meaning vector. Then train on that pair.
- need to see what it can do on forms it's never seen, can it do wug tests? can it interpret the meaning of a form whose morphemes it knows but the whole of which it hasn't seen?
- can we make an agent-based game with NNs trained like this and see if they undergo language change over time? would want sound changes and meaning changes, and resultant changes in the form-meaning mappings. If morphemes are generalizations over words, expect new morphemes to arise after enough changes have happened and new patterns appear that the agents can notice.
